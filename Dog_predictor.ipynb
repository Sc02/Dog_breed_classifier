{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchit/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to read image .DS_Store in category Beagle\n",
      "Warning: Unable to read image .DS_Store in category Boxer\n",
      "Warning: Unable to read image .DS_Store in category Bulldog\n",
      "Warning: Unable to read image .DS_Store in category Husky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to read image .DS_Store in category Labrador_Retriever\n",
      "Warning: Unable to read image .DS_Store in category Poodle\n",
      "Warning: Unable to read image .DS_Store in category Yorkshire_Terrier\n",
      "Data preparation complete.\n",
      "Total samples: 1056\n"
     ]
    }
   ],
   "source": [
    "DataDir = \"dataset\"\n",
    "categories = [\"Beagle\", \"Boxer\", \"Bulldog\", \"Dachshund\", \"German_Shepherd\", \"Golden_Retriever\", \"Husky\", \"Labrador_Retriever\", \"Poodle\", \"Rottweiler\", \"Yorkshire_Terrier\"]\n",
    "\n",
    "training_data = []\n",
    "img_size = 70\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(DataDir, category)\n",
    "        y_value = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                if img_array is not None:\n",
    "                    new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                    training_data.append([new_array, y_value])\n",
    "                else:\n",
    "                    print(f\"Warning: Unable to read image {img} in category {category}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img} in category {category}: {e}\")\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "# Shuffle the data to ensure a good mix of classes\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "# Separate features and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "# Convert to NumPy arrays and reshape\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize the pixel values\n",
    "X = X / 255.0\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Total samples: {len(training_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DataDir = \"dataset\"\n",
    "categories = [\"Beagle\", \"Boxer\", \"Bulldog\", \"Dachshund\", \"German_Shepherd\", \"Golden_Retriever\", \"Husky\", \"Labrador_Retriever\", \"Poodle\", \"Rottweiler\", \"Yorkshire_Terrier\"]\n",
    "\n",
    "def count_images_per_breed():\n",
    "    breed_counts = {}\n",
    "    for category in categories:\n",
    "        path = os.path.join(DataDir, category)\n",
    "        if os.path.exists(path):\n",
    "            num_images = len([img for img in os.listdir(path) if os.path.isfile(os.path.join(path, img))])\n",
    "            breed_counts[category] = num_images\n",
    "        else:\n",
    "            breed_counts[category] = 0\n",
    "    return breed_counts\n",
    "\n",
    "breed_counts = count_images_per_breed()\n",
    "\n",
    "for breed, count in breed_counts.items():\n",
    "    print(f\"{breed}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchit/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.0767 - loss: 2.4149 - val_accuracy: 0.0755 - val_loss: 2.3976\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.1096 - loss: 2.3943 - val_accuracy: 0.1415 - val_loss: 2.3670\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.1773 - loss: 2.2967 - val_accuracy: 0.4151 - val_loss: 1.9700\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.3341 - loss: 1.9133 - val_accuracy: 0.5849 - val_loss: 1.4083\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.5319 - loss: 1.3281 - val_accuracy: 0.7925 - val_loss: 0.8498\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.7032 - loss: 0.8871 - val_accuracy: 0.8585 - val_loss: 0.5486\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.8044 - loss: 0.6628 - val_accuracy: 0.8868 - val_loss: 0.3651\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.8835 - loss: 0.3985 - val_accuracy: 0.9528 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9106 - loss: 0.3496 - val_accuracy: 0.9434 - val_loss: 0.1993\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9282 - loss: 0.2490 - val_accuracy: 0.9623 - val_loss: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "num_classes = 11\n",
    "\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X = np.array(X)\n",
    "if not isinstance(y, np.ndarray):\n",
    "    y = np.array(y)\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "#building the model and adding the layers\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_size, img_size, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Layer 3\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(X, y, batch_size=32, validation_split=0.1, epochs=10, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Save the model\n",
    "model.save('dog_breed_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#predicting the image\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('dog_breed_classifier.h5')\n",
    "\n",
    "def prepare_image(filepath, img_size=70):\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # Read the image in grayscale\n",
    "    new_array = cv2.resize(img_array, (img_size, img_size))  # Resize the image to match the input shape\n",
    "    new_array = new_array.reshape(-1, img_size, img_size, 1)  # Reshape the image to add batch dimension\n",
    "    new_array = new_array / 255.0  # Normalize the image\n",
    "    return new_array\n",
    "\n",
    "def predict_breed(filepath):\n",
    "    prepared_image = prepare_image(filepath)\n",
    "    prediction = model.predict(prepared_image)\n",
    "    breed_index = np.argmax(prediction)\n",
    "    breed_name = categories[breed_index]\n",
    "    return breed_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'path_to_your_dog_image.jpg'\n",
    "breed_name = predict_breed(image_path)\n",
    "print(f\"The predicted breed is: {breed_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
